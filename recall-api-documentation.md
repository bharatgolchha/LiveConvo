# Recall.ai API Documentation for LivePrompt.ai

## Overview

Recall.ai provides a universal API for creating meeting bots that can join video conferencing platforms (Zoom, Google Meet, Microsoft Teams) to capture audio, video, and transcripts in real-time.

## Key Features

- **Multi-platform Support**: Single API for all major video conferencing platforms
- **Real-time Transcription**: Stream transcripts via webhooks with <1 second latency
- **Multiple Transcription Providers**: Deepgram, Speechmatics, Rev, or Recall's own AI
- **Speaker Diarization**: Automatic speaker identification and separation
- **Participant Events**: Track joins, leaves, speaking times
- **No Downloads Required**: Bots join meetings without user installation

## Authentication

```http
Authorization: Token YOUR_API_KEY
```

All API requests require a token in the Authorization header.

## Core API Endpoints

### 1. Create Bot
```typescript
POST https://us-east-1.recall.ai/api/v1/bot

{
  "meeting_url": "https://zoom.us/j/123456789",
  "bot_name": "LivePrompt Assistant",
  "metadata": {
    "session_id": "uuid-here",
    "source": "liveprompt"
  },
  "recording_config": {
    "transcript": {
      "provider": { "deepgram": {} }  // or speechmatics, rev, recall_ai
    },
    "video_mixed_layout": "audio_only",
    "realtime_endpoints": [{
      "type": "websocket",
      "config": {
        "url": "wss://your-app.com/webhooks/recall/session-id",
        "events": [
          "transcript.sentence",
          "participant.events", 
          "recording.completed"
        ]
      }
    }]
  }
}
```

**Response:**
```json
{
  "id": "bot-uuid",
  "status": "created",
  "meeting_url": "https://zoom.us/j/123456789",
  "created_at": "2024-01-01T00:00:00Z"
}
```

### 2. Get Bot Status
```typescript
GET https://us-east-1.recall.ai/api/v1/bot/{bot_id}
```

**Response:**
```json
{
  "id": "bot-uuid",
  "status": "in_call",  // created, joining, in_call, completed, failed
  "recordings": [{
    "id": "recording-uuid",
    "status": "recording"
  }]
}
```

### 3. Stop Bot
```typescript
POST https://us-east-1.recall.ai/api/v1/bot/{bot_id}/leave_call
```

### 4. Get Recording/Transcript
```typescript
GET https://us-east-1.recall.ai/api/v1/transcript/{recording_id}
```

## Real-time Transcription

### Overview
Real-time transcription allows you to consume transcript utterances generated by the bot via Real-Time Endpoints. This enables streaming transcripts with extremely low latency (typically <1 second).

### Configuration
To configure a bot for real-time transcription, your Create Bot request must include:
- A webhook Real-Time Endpoint configured with the `transcript.data` event
- A transcript artifact configured with the provider of your choice

```bash
curl --request POST \
     --url https://us-west-2.recall.ai/api/v1/bot/ \
     --header "Authorization: Token $RECALL_AI_API_KEY" \
     --header "accept: application/json" \
     --header "content-type: application/json" \
     --data '
{
  "meeting_url": "https://meet.google.com/abc-defg-hij",
  "bot_name": "LivePrompt Assistant",
  "recording_config": {
    "transcript": {
      "provider": {
        "deepgram": {}
      }
    },
    "realtime_endpoints": [
      {
        "type": "webhook",
        "url": "https://app.liveprompt.ai/api/webhooks/recall/session-id",
        "events": ["transcript.data", "transcript.partial_data"]
      }
    ]
  }
}
'
```

### Webhook Payload Structure

#### Final Transcript Event
When a finalized transcript utterance is ready:

```json
{
  "event": "transcript.data",
  "data": {
    "data": {
      "words": [{
        "text": "Hello",
        "start_timestamp": { "relative": 1.0 },
        "end_timestamp": { "relative": 1.5 }
      }],
      "participant": {
        "id": 1,
        "name": "John Doe",
        "is_host": true,
        "platform": "zoom",
        "extra_data": {}
      }
    },
    "realtime_endpoint": {
      "id": "endpoint-uuid",
      "metadata": {}
    },
    "transcript": {
      "id": "transcript-uuid",
      "metadata": {}
    },
    "recording": {
      "id": "recording-uuid",
      "metadata": {}
    },
    "bot": {
      "id": "bot-uuid",
      "metadata": { "session_id": "your-session-id" }
    }
  }
}
```

#### Partial Results (Low Latency)
For reduced latency, you can receive partial/intermediate results:

```json
{
  "event": "transcript.partial_data",
  "data": {
    "data": {
      "words": [{
        "text": "Hey my name is",
        "start_timestamp": { "relative": 1.0 },
        "end_timestamp": { "relative": 2.0 }
      }],
      "participant": {
        "id": 1,
        "name": "John Doe",
        "is_host": true
      }
    }
    // ... same structure as above
  }
}
```

### Using Partial Results

Partial results provide a real-time experience by sending incomplete utterances quickly, followed by the final accurate version:

1. **Partial results** (event = `transcript.partial_data`):
   - "Hey my name"
   - "Hey my name is John"
   - "Hey my name is John, it's really nice"

2. **Final result** (event = `transcript.data`):
   - "Hey, my name is John. It's really nice to meet you."

Common pattern: Display partial results in UI immediately, then replace with finalized version when received.

### Important Considerations

#### Concurrency Limits
⚠️ **Production Requirement**: Ensure your transcription provider account has sufficient concurrency limits for your anticipated load. Contact your provider to increase limits before production deployment.

#### Webhook Processing
- Transcription webhooks are sequential and order-dependent
- Blocking webhook processing will delay subsequent webhooks
- Process webhooks asynchronously to prevent delays
- Typical frequency: 100ms to low seconds for partial results

#### Language Support
Some providers support automatic language detection:

| Provider | Configuration | Languages |
|----------|--------------|-----------|
| assembly_ai_streaming | `language_detection: true` | [Docs](https://docs.assemblyai.com) |
| aws_transcribe_streaming | `language_identification: true` with `language_options` | [Docs](https://docs.aws.amazon.com) |
| gladia_streaming | `language_behaviour: "automatic single language"` | [Docs](https://docs.gladia.io) |

### Full Transcript Access
In addition to real-time webhooks, the complete transcript is available via the bot's recording:

```typescript
GET https://us-west-2.recall.ai/api/v1/bot/{bot_id}

// Response includes:
{
  "recordings": [{
    "media_shortcuts": {
      "transcript": {
        "data": {
          "download_url": "https://..."
        }
      }
    }
  }]
}
```

### Error Handling
If real-time transcription fails, fall back to async transcription or alternative providers.

## Real-time Webhook Events

### 1. Transcript Data Event (Final)
```json
{
  "event": "transcript.sentence",
  "data": {
    "speaker": {
      "id": 1,
      "name": "John Doe",
      "is_host": true
    },
    "words": [{
      "text": "Hello",
      "start_time": 1.0,
      "end_time": 1.5,
      "confidence": 0.98
    }],
    "text": "Hello everyone, welcome to the meeting",
    "start_time": 1.0,
    "end_time": 3.5
  },
  "bot": {
    "id": "bot-uuid",
    "metadata": { "session_id": "your-session-id" }
  }
}
```

### 2. Participant Events
```json
{
  "event": "participant.events", 
  "data": {
    "type": "joined",  // joined, left, started_speaking, stopped_speaking
    "participant": {
      "id": 2,
      "name": "Jane Smith",
      "is_host": false
    },
    "timestamp": 1234567890
  }
}
```

### 3. Recording Completed
```json
{
  "event": "recording.completed",
  "data": {
    "recording_id": "recording-uuid",
    "duration_seconds": 1800,
    "download_urls": {
      "transcript": "https://...",
      "audio": "https://..."
    }
  }
}
```

## WebSocket Handler Example

```typescript
import WebSocket from 'ws';
import fs from 'fs';

interface TranscriptEvent {
  event: 'transcript.sentence';
  data: {
    speaker: {
      id: number;
      name: string;
      is_host: boolean;
    };
    text: string;
    words: Array<{
      text: string;
      start_time: number;
      end_time: number;
      confidence: number;
    }>;
  };
}

const wss = new WebSocket.Server({ port: 3456 });

wss.on('connection', (ws) => {
  ws.on('message', (message: WebSocket.Data) => {
    try {
      const event = JSON.parse(message.toString());
      
      switch (event.event) {
        case 'transcript.sentence':
          handleTranscript(event as TranscriptEvent);
          break;
        case 'participant.events':
          handleParticipantEvent(event);
          break;
        case 'recording.completed':
          handleRecordingComplete(event);
          break;
      }
    } catch (error) {
      console.error('WebSocket error:', error);
    }
  });
});

function handleTranscript(event: TranscriptEvent) {
  const { speaker, text, words } = event.data;
  console.log(`${speaker.name}: ${text}`);
  
  // Process for your application
  saveTranscriptToDatabase({
    speaker: speaker.name,
    text: text,
    confidence: words.reduce((acc, w) => acc + w.confidence, 0) / words.length,
    timestamp: new Date(words[0].start_time * 1000)
  });
}
```

## Recording Configuration Options

### Transcription Providers
```typescript
// Deepgram (recommended for general use)
"transcript": { "provider": { "deepgram": {} } }

// Speechmatics (good for accents)
"transcript": { "provider": { "speechmatics": {} } }

// Rev (human-quality)
"transcript": { "provider": { "rev": {} } }

// Recall AI (cost-effective)
"transcript": { "provider": { "recall_ai": {} } }
```

### Video Layouts
- `audio_only` - No video, audio only (recommended for transcription)
- `speaker_view` - Active speaker video
- `gallery_view` - Grid of all participants
- `gallery_view_v2` - Enhanced gallery with separate streams

### Advanced Features

#### Separate Audio Streams
```json
{
  "recording_config": {
    "audio_separate_raw": {},
    "realtime_endpoints": [{
      "type": "websocket",
      "config": {
        "url": "wss://your-app.com/webhook",
        "events": ["audio_separate_raw.data"]
      }
    }]
  }
}
```

#### Real-time Video Frames
```json
{
  "recording_config": {
    "video_separate_png": {},
    "realtime_endpoints": [{
      "type": "websocket", 
      "config": {
        "url": "wss://your-app.com/webhook",
        "events": ["video_separate_png.data"]
      }
    }]
  }
}
```

## Bot Behavior & Status Codes

### Bot Lifecycle
1. `created` - Bot created, not yet joining
2. `joining` - Bot attempting to join meeting
3. `in_call` - Bot successfully in meeting
4. `in_call_not_recording` - In meeting but not recording
5. `in_call_recording` - Actively recording
6. `completed` - Recording finished successfully
7. `failed` - Bot failed to join or error occurred

### Common Error Codes
- `meeting_not_started` - Meeting hasn't begun
- `meeting_ended` - Meeting already finished
- `invalid_meeting_url` - URL not recognized
- `bot_limit_reached` - Too many concurrent bots
- `permission_denied` - Bot blocked by host

## Rate Limits

- **Create Bot**: 60 requests/min per workspace
- **Get Bot**: 300 requests/min per workspace
- **Start Recording**: 300 requests/min per workspace

## Pricing

- **Base cost**: $0.004/minute of recording
- **Additional costs**:
  - Transcription: Varies by provider (~$0.006/min)
  - Video recording: +$0.002/minute
  - Separate streams: +$0.001/minute per stream

## Best Practices

### 1. Error Handling
```typescript
async function createBotWithRetry(meetingUrl: string, retries = 3) {
  for (let i = 0; i < retries; i++) {
    try {
      const bot = await createBot({ meeting_url: meetingUrl });
      return bot;
    } catch (error) {
      if (error.status === 429) {
        // Rate limited, wait and retry
        await sleep(Math.pow(2, i) * 1000);
      } else if (error.status >= 500) {
        // Server error, retry
        await sleep(1000);
      } else {
        // Client error, don't retry
        throw error;
      }
    }
  }
  throw new Error('Failed to create bot after retries');
}
```

### 2. Webhook Reliability
```typescript
// Store webhooks for replay if processing fails
async function handleWebhook(event: any) {
  // Store raw event first
  await storeWebhookEvent(event);
  
  try {
    await processWebhookEvent(event);
    await markWebhookProcessed(event.id);
  } catch (error) {
    console.error('Webhook processing failed:', error);
    // Will be retried later
  }
}
```

### 3. Cost Optimization
```typescript
const recordingConfig = {
  // Only record what you need
  video_mixed_layout: "audio_only",  // No video if not needed
  
  // Choose appropriate provider
  transcript: {
    provider: {
      recall_ai: {}  // Cheapest option
    }
  },
  
  // Stop recording when done
  automatic_leave: {
    waiting_room_timeout: 300,  // Leave after 5 min in waiting room
    noone_joined_timeout: 600   // Leave if alone for 10 min
  }
};
```

### 4. Security Considerations
- Always use HTTPS/WSS for webhooks
- Validate webhook events are from Recall
- Don't expose bot IDs to end users
- Implement proper access controls

## Integration with LivePrompt.ai

### Session Creation Flow
1. User provides meeting URL in modal
2. Create session in database
3. Create Recall bot with session metadata
4. Store bot ID with session
5. Handle webhooks for real-time updates

### Real-time Transcription Implementation

Our implementation uses the real-time transcription webhook format with both partial and final results:

```typescript
// Bot creation configuration
recording_config: {
  transcript: {
    provider: { deepgram: {} }  // Using Deepgram for quality
  },
  realtime_endpoints: [{
    type: 'webhook',
    url: `https://app.liveprompt.ai/api/webhooks/recall/${sessionId}`,
    events: [
      'transcript.data',        // Final transcripts
      'transcript.partial_data', // Partial results for low latency
      'participant.events',
      'recording.completed'
    ]
  }]
}
```

### Webhook Processing
1. **Partial Transcripts** (`transcript.partial_data`):
   - Broadcast immediately to UI via Server-Sent Events
   - Not stored in database
   - Marked with `isFinal: false` and `isPartial: true`
   - Provides real-time feedback with <1s latency

2. **Final Transcripts** (`transcript.data`):
   - Store in transcripts table with sequence number
   - Update session statistics
   - Broadcast to UI with `isFinal: true`
   - Trigger AI guidance as needed

3. **Speaker Identification**:
   - `is_host: true` → Speaker: "ME" (meeting host)
   - `is_host: false` → Speaker: "THEM" (participant)
   - Use participant names from session configuration

### Fallback Strategy
```typescript
class TranscriptionManager {
  async startTranscription(session: Session) {
    if (session.meeting_url) {
      try {
        // Try Recall.ai for meeting URLs
        return await this.startRecallBot(session);
      } catch (error) {
        console.error('Recall bot failed:', error);
        // Fall back to Deepgram browser recording
        return await this.startDeepgram(session);
      }
    } else {
      // Use Deepgram for local recording
      return await this.startDeepgram(session);
    }
  }
}
```

## Troubleshooting

### Bot Won't Join
- Check meeting URL format
- Ensure meeting has started
- Verify host permissions
- Check rate limits

### No Transcripts Received
- Verify webhook URL is accessible
- Check WebSocket connection
- Ensure transcription provider is set
- Look for webhook errors

### Poor Transcription Quality
- Try different providers
- Check audio quality settings
- Verify speaker microphones
- Consider custom vocabulary

## Support & Resources

- API Reference: https://docs.recall.ai/
- Status Page: https://status.recall.ai/
- Support: support@recall.ai
- Rate Limits: https://docs.recall.ai/docs/rate-limits

## Desktop SDK (Alternative Approach)

For privacy-conscious users who don't want bots joining:

```typescript
import RecallAiSdk from '@recallai/desktop-sdk';

RecallAiSdk.init({
  api_url: "https://us-east-1.recall.ai"
});

RecallAiSdk.addEventListener('meeting-detected', async (evt) => {
  // Automatically detect and record local meetings
  await RecallAiSdk.startRecording({
    windowId: evt.window.id,
    uploadToken: await getUploadToken()
  });
});
```

This SDK captures any meeting on the user's screen without joining as a bot.